\documentclass[a4paper,twoside]{article}
\input{../../preamble.tex}
\title{33-756 Homework 1}
\date{\today}
\begin{document}
\maketitle

\section*{1. Representations of Rotational Groups}
In class we said that the Lie Algebra of a group almost determines the group exactly. We will now see why the qualifier is there. This problem will deal with the group of rotations whose three generators obey the familiar relation
\begin{equation}
    \comm{J_i}{J_j} = \imath \hbar J_k.
\end{equation}
\begin{itemize}
    \item[a.] Consider the collection of 3 by 3 matrices which act as rotations on three-dimensional Euclidean space. Note, this is one particular (3D) representations of a group. This is the defining representation of the group $ SO(3) $. Show that these matrices are orthogonal ($ O^T = O^{-1} $). Hint: Use the fact that rotations preserve the length of a vector to prove orthogonality. Next prove that the determinant must be $ \pm 1 $. Hint: use $ \det(O) = \det(O^T) $ and $ \det(AB) = \det(A)\det(B) $. Thus rotation matrices need not be elements of $ SO(3) $ since the determinant could be $ -1 $. If we were to allow for either sign for the determinant, then this would be the group $ O(3) $. Show that restricting to matrices with determinant one, still forms a group.
        \begin{problem}
            Rotations preserve the length of a vector. The length can be defined as $\va{ x}^T \vdot\va{ x} $. The transformation of $\va{ x} $ under a rotational matrix is $ O\va{ x} $, so
            \begin{equation}
                \va{ x}^T \vdot\va{ x} = \left( O\va{ x} \right)^T \vdot\left( O\va{ x} \right) =\va{ x}^T O^T O\va{ x}
            \end{equation}
            so $ O^T O = I $ or $ O^T = O^{-1} $.
        \end{problem}
        \begin{problem}
            To prove that the determinant must be $ \pm 1 $, we know that
            \begin{equation}
                1 = \det(I)
            \end{equation}
            and that
            \begin{equation}
                I = O^T O
            \end{equation}
            so
            \begin{equation}
                1 = \det(I) = \det(O^T O) = \det(O^T)\det(O) = \left( \det(O) \right)^2
            \end{equation}
            so $ \det(O) = \sqrt{1} = \pm 1 $.
        \end{problem}
        \begin{problem}
            If we further restrict to matrices with $ \det(O) = +1 $, we know that multiplying group elements must result in another group element, so
            \begin{equation}
                O_a O_b = O_c.
            \end{equation}
            Since $ \det(O_a O_b) = \det(O_a)\det(O_b) $, then $ \det(O_a O_b) = +1 $, so $ \det(O_c) = +1 $, meaning that $ O_c $ is a group element, so rotation matrices with positive determinant form a group.
        \end{problem}

    \item[b.] Next show that $ \sigma_i/2 $ obey the commutation relation for the group $ SO(3) $. Where $ \sigma_i $ are the Pauli matrices. Naively we might think this the means representation generated by the Pauli matrices belong to the group $ SO(3) $, but this is wrong!\ As we shall now see.
        \begin{problem}
            The Pauli matrices are defined as
            \begin{equation}
                \sigma_1 = \mqty(0&1\\1&0) \quad \sigma_2 = \mqty(0&- \imath\\ \imath &0) \quad \sigma_3 = \mqty(1&0\\0&-1)
            \end{equation}
            or
            \begin{equation}
                \sigma_a = \mqty(\delta_{a3} & \delta_{a1} - \imath \delta_{a2} \\ \delta_{a1 + \imath \delta_{a2}} & - \delta_{a3})
            \end{equation}
            The commutator of two of these matrices (divided by two) is
            \begin{equation}
                \comm{\frac{\sigma_a}{2}}{\frac{\sigma_b}{2}} = \frac{\imath}{2} \mqty(\delta_{a1} \delta_{b2} - \delta_{a2} \delta_{b1} & (\delta_{a2} \delta_{b3} - \delta_{a3} \delta_{b2}) - \imath (\delta_{a3} \delta_{b1} - \delta_{a1} \delta_{b3}) \\ (\delta_{a2} \delta_{b3} - \delta_{a3} \delta_{b2})+ \imath (\delta_{a3} \delta_{b1} - \delta_{a1} \delta_{b3}) & -(\delta_{a1} \delta_{b2} - \delta_{a2} \delta_{b1}))
            \end{equation}
            These groupings of $\delta$-functions can be converted into contracted $\epsilon$-identities using the Levi-Civita symbol, since $ \epsilon_{ijk} \epsilon_{ilm} = \delta_{jl} \delta_{km} - \delta_{jm} \delta_{kl} $. I'll call the contracted index $ c $ (this choice will be obvious later):
            \begin{equation}
                \comm{\frac{\sigma_a}{2}}{\frac{\sigma_b}{2}} = \frac{\imath}{2} \mqty(\epsilon_{cab} \epsilon_{c12} & \epsilon_{cab} \epsilon_{c23} - \imath (\epsilon_{cab} \epsilon_{c31}) \\ \epsilon_{cab} \epsilon_{c23} + \imath (\epsilon_{cab} \epsilon_{c31}) & -(\epsilon_{cab} \epsilon_{c12})) 
            \end{equation}
            There is a common factor of $ \epsilon_{cab} $ (or equivalently $ \epsilon_{abc} $) which can be factored out of this matrix. I also will include some cyclic transformations of the indices in the other symbols:
            \begin{equation}
                \comm{\frac{\sigma_a}{2}}{\frac{\sigma_b}{2}} = \frac{\imath}{2} \epsilon_{abc} \mqty(\epsilon_{12c} & \epsilon_{c23} - \imath \epsilon_{1c3} \\ \epsilon_{c23} + \imath \epsilon_{1c3} & - \epsilon_{12c}) 
            \end{equation}
            Since there are only three possible Pauli matrices, all of the Levi-Civita symbols inside the matrix will become $\delta$-functions, since, for example
            \begin{equation}
                \epsilon_{12c} = \begin{cases} 0 & c=1,2 \\ 1 & c=3 \end{cases} = \delta_{c3}.
            \end{equation}
            Therefore, the commutator becomes
            \begin{equation}
                \comm{\frac{\sigma_a}{2}}{\frac{\sigma_b}{2}} = \frac{\imath}{2} \epsilon_{abc} \mqty(\delta_{c3} & \delta_{c1} - \imath \delta_{c2} \\ \delta_{c1} + \imath \delta_{c2} & - \delta_{c3}) = \imath \epsilon_{abc} \frac{\sigma_c}{2}
            \end{equation}
            which is the commutation relation for $ SO(3) $.
        \end{problem}

    \item[c.] Now we also said that given a representation of the algebra we could write down any group element by exponentiating the generators. Given the fact that the algebra has three generators, we need three real numbers to fix the group element, call them $ \alpha_i $. We can write this vector in terms of a directional unit vector $\vu{ n} $ and the amplitude of the rotation angle $ \theta $: $ \va{\alpha} =\vu{ n} \theta $. Show that these exponentials all have determinant one and are unitary.
        \begin{problem}
            We have just shown that the Pauli matrices can act as generators of $ SO(3) $. Our exponentials are of the form
            \begin{equation}
                g(\alpha_i) = e^{\imath \alpha_i \sigma_i/2} = e^{\imath \theta (\vu{n}_i \sigma_i/2)}
            \end{equation}
            
            We can use Jacobi's formula to find the determinant:
            \begin{equation}
                \det(e^{A}) = e^{\Tr(A)}
            \end{equation}
            The Pauli matrices are traceless, so $ \Tr(\sigma_i/2) = 0 $. Therefore $ \det(e^{\imath \alpha_i \sigma_i/2}) = e^{\imath \alpha_i \Tr(\sigma_i/2)} = e^{0} = +1 $.

            The conjugate transpose of an exponentiated matrix is the exponential of its conjugate transpose:
            \begin{equation}
                (e^{X})^T = e^{X^T}
            \end{equation}
            so
            \begin{align}
                \left(e^{\imath \theta\vu{ n} \vdot \va{\sigma}/2}\right)^\dagger e^{\imath \theta\vu{ n} \vdot \va{\sigma}/2} &= e^{- \imath \theta(\vu{n} \vdot \va{\sigma}/2)^\dagger} e^{\imath \theta\vu{ n} \vdot \va{\sigma}/2} \\
                &= e^{\imath \theta\vu{ n}_i (\sigma_i - \sigma_i^\dagger)/2} \\
                &= e^{0_{3,3}} = I
            \end{align}
            since the Pauli matrices are Hermitian, or $ \sigma_i^\dagger = \sigma_i $. $ g(\va{\alpha})^\dagger g(\va{\alpha}) = I $ is the defining property of $ g $ being unitary.
        \end{problem}

    \item[d.] Show that the associated representation of this group element is given by
        \begin{equation}
            g(\alpha_i) = \cos(\frac{\theta}{2}) + \imath\vu{ n}_i \vdot \sigma_i\sin(\frac{\theta}{2})
        \end{equation}
        \begin{problem}
            This can be done by expanding the exponential:
            \begin{align}
                e^{\imath \theta (\vu{n} \vdot \va{\sigma}/2)} &= \sum_{j=0}^{\infty} \frac{\imath^j}{j!} \left( \frac{\theta}{2} (\vu{n} \vdot \va{\sigma}) \right)^j \\
                &= \sum_{j=0}^{\infty} \left( \frac{(-1)^j}{(2j)!} \left( \frac{\theta}{2} \right)^{2j} \left(\vu{ n} \vdot \va{\sigma} \right)^{2j} \right) + \imath \left( \frac{(-1)^j}{(2j + 1)!} \left( \frac{\theta}{2} \right)^{2j+1} (\vu{n} \vdot \sigma)^{2j + 1} \right)
            \end{align}
            The Pauli matrices are involutory ($ \sigma_i^2 = I $) so $ (\vu{n} \vdot \va{\sigma})^{2j} = I $ and $ (\vu{n} \vdot \va{\sigma})^{2j+1} = (\vu{n} \vdot \va{\sigma}) $.
            \begin{equation}
                g(\va{\alpha}) = e^{\imath \frac{\theta}{2} (\vu{n} \vdot \va{\sigma})} = I \sum_{j=0}^{\infty} (-1)^j\frac{\left( \frac{\theta}{2} \right)^{2j}}{(2j)!} + \imath (\vu{n} \vdot \va{\sigma}) \sum_{j=0}^{\infty} (-1)^j \frac{\left( \frac{\theta}{2} \right)^{2j+1}}{(2j+1)!} = I \cos(\frac{\theta}{2}) + \imath (\vu{n} \vdot \va{\sigma}) \sin(\frac{\theta}{2})
            \end{equation}
        \end{problem}

    \item[e.] Show that this representation DOES NOT form a representation of the rotation group $ SO(3) $. Instead this exponential is a representation of the group $ SU(2) $. The group defined by two dimensional unitary matrices with unit determinant. Show that $ g $ obey both these properties.
        \begin{problem}
            First, we will show the group is defined by unitary matrices ($ g(\alpha_i)^\dagger g(\alpha_i) = I $):
            \begin{align}
                g(\alpha_i)^\dagger g(\alpha_i) &= (I \cos(\frac{\theta}{2}) - \imath\vu{ n}_i \sigma_i \sin(\frac{\theta}{2}) )(I \cos(\frac{\theta}{2}) + \imath\vu{ n}_i \sigma_i \sin(\frac{\theta}{2})) \\
                &= I^2 \cos[2](\frac{\theta}{2}) +(\vu{ n}  \sigma_i)^2 \sin[2](\frac{\theta}{2}) \\
                &= I\cos[2](\frac{\theta}{2}) + I\sin[2](\frac{\theta}{2}) \\
                &= I
            \end{align}
            To find the determinant of the sum of two matrices, unfortunately we'll just have to write down each case (there's probably an better way, but this isn't too hard to do).
            \begin{equation}
                \det(g(\alpha_1)) = \mdet{\cos(\frac{\theta}{2}) & \imath\vu{ n} \sin(\frac{\theta}{2}) \\ \imath\vu{ n} \sin(\frac{\theta}{2}) & \cos(\frac{\theta}{2})} = \cos[2](\frac{\theta}{2}) + \sin[2](\frac{\theta}{2}) = 1
            \end{equation}
            \begin{equation}
                \det(g(\alpha_2)) = \mdet{ \cos(\frac{\theta}{2}) & \vu{ n} \sin(\frac{\theta}{2}) \\ -\vu{ n} \sin(\frac{\theta}{2}) & \cos(\frac{\theta}{2})} = \cos[2](\frac{\theta}{2}) + \sin[2](\frac{\theta}{2}) = 1
            \end{equation}
            and
            \begin{equation}
                \det(g(\alpha_3)) = \mdet{ \cos(\frac{\theta}{2}) + \vu{ n} \sin(\frac{\theta}{2}) \\ 0 & \cos(\frac{\theta}{2}) -\vu{ n} \sin(\frac{\theta}{2})} = \cos[2](\frac{\theta}{2}) + \sin[2](\frac{\theta}{2}) = 1
            \end{equation}

            Since these are a representation of $ SU(2) $, they are unitary, and they are not orthogonal, due to the complex $ \imath $ multiplying the Pauli matrices (and the second Pauli matrix is complex), meaning the transpose and the conjugate transpose are not the same.
        \end{problem}

    \item[f.] Show that the space group transformation corresponds to a three dimensional sphere, usually written as $ S^3 $. Hint: recall that a $ d $-dimensional sphere can be written as the surface $ x_1^2 + x_2^2 + \cdots + x_{d+1}^2 = R^2 $ embedded in a $ d + 1 $ dimensional space. Then write the most general form for an element of $ SU(2) $ and show that its parameters must live in $ S^3 $. $ S^3 $, in this case, is called the group manifold.
        \begin{problem}
            In general, we can write elements of $ SU(2) $ as
            \begin{equation}
                SU(2) =  \left\{ \mqty(\alpha & - \bar{\beta} \\ \beta & \bar{\alpha}) \mid \alpha, \beta \in \mathbb{C}, \abs{\alpha}^2 + \abs{\beta}^2 = 1\right\}
            \end{equation}
            The second restriction is the ``special'' part; The matrices must have unit determinant. If we consider these values to be complex (which we do), we can assign $ \alpha = a + b \imath $ and $ \beta = c + d \imath $. The restriction of unit determinant now becomes
            \begin{equation}
                a^2 + b^2 + c^2 + d^2 = 1
            \end{equation}
            the equation for a general $ 3 $-sphere.
        \end{problem}

    \item[g.] We just determined that the group manifold of $ SU(2) $ is $ S^3 $. Show that the group manifold for $ SO(3) $ is a three-dimensional ball $ B^3 $ with antipodal points identified. This is written as $ B^3 / Z_2 $. $ SU(2) $ is known as the ``covering group'' of $ SO(3) $ because it double covers $ SO(3) $, in the sense that for each element of $ SO(3) $ there are two corresponding elements of $ SU(2) $, e.g. $ 0 $ and $ 2 \pi $ are the same rotation in $ SO(3) $ but NOT in $ SU(2) $.
        \begin{problem}
            If we consider $ SO(3) $ as rotations around a unit vector $\vu{ n} $ with a magnitude $ \theta $, the space of all possible rotations will be a ball of radius $ \pi $, where each point in the ball can be represented by the vector $\vu{ n} \theta $. Rotations greater than $ \pi $ are equivalent to rotations in the opposite direction, points on the surface of the sphere are identified to antipodal points (since rotation by $ \pi $ in one direction is equivalent to rotation by $ \pi $ in the opposite direction).
        \end{problem}

    \item[h.] Show that for every element of $ SO(3) $ there are two elements of $ SU(2) $. To do so first show that
        \begin{equation}
            \det(\va{x} \vdot \sigma) = -\va{ x}^2.
        \end{equation}
        Then show that a similarity transformation of the form
        \begin{equation}
            \va{ x} \vdot \sigma \to G^{-1}\va{ x} \vdot \va{\sigma} G
        \end{equation}
        acts as a rotation on $\va{ x} $ where $ G $ is an element of $ SU(2) $, and use this result to show that that there are two elements of $ SU(2) $ for every rotation.
        \begin{problem}
            We can first write the general determinant:
            \begin{equation}
                \det(\va{x} \vdot \sigma) = \mdet{x_3 & x_1 - \imath x_2 \\ x_1 + \imath x_2 & - x_3} = - x_1^2 - x_2^2 - x_3^2 = -\va{ x}^2
            \end{equation}

            Technically, $ -\va{ x}^2 = -(\va{ x} \vdot \va{\sigma})^2 $ since $ \va{\sigma}^2 = 1 $.

            Since $ G $ has unit determinant, $ \det(\va{x} \vdot \va{\sigma}) = \det(G^{-1}\va{ x} \vdot \va{\sigma} G) $. All together,
            \begin{equation}
                (\va{x} \vdot \va{\sigma})^2 = -\det(\va{x} \vdot \va{\sigma}) = -\det(G^{-1}\va{ x} \vdot \va{\sigma} G)
            \end{equation}
            Therefore, the similarity transformation preserves the inner product and is an orthogonal transformation. To prove that it is a rotation, we need to show that the determinant of $ G^{-1}\va{ x} \vdot \va{\sigma} G $ is positive and unit valued. This follows from the fact that both of the elements $ G $ in our transform are elements of $ SU(2) $, which by definition mean they have $ +1 $ determinants. We can map two elements of $ SU(2) $ to one element in $ SO(3) $ since we could have used $ -G $ and $ -G^{-1} $ and the minus signs would've canceled out to give us the same transformation:
            \begin{equation}
                (- G^{-1})\va{ x} \vdot \va{\sigma} (-G) = (G^{-1})\va{ x} \vdot \va{\sigma} (G) \in SO(3)
            \end{equation}
    \end{problem}
\end{itemize}

\section*{2. Symmetries of an Action}
Consider the one dimensional action
\begin{equation}
    S = \int \dd{t} \left( \frac{1}{2} m \dot{x}^2 - \frac{\alpha}{x^2} \right)
\end{equation}
This system is remarkable in that we can solve the equations of motion just by using symmetries, i.e. we don't have to solve any differential equations at all. The reason is that the system is highly symmetric. What are these symmetries?

\begin{problem}
    This action is symmetric under inversions: $ x \mapsto -x $ but the only $ x $-term is $ x^2 $ which is even and will not change under parity. Additionally, there are no terms which scale with time, so the action is invariant under time translations. According to problem 3, it is also invariant under time scaling transformations.
\end{problem}

\section*{3. Time Translation Invariance}
Show that time translation invariance implies that energy is conserved
\begin{equation}
    E = \frac{1}{2} m \dot{x}^2 + \frac{\alpha}{x^2}
\end{equation}
This equation fixed $ \dot{x} $ in terms of $ x $. But there is more symmetry here.

Consider the transformation
\begin{equation}
    t \to t' = \lambda t \quad x(t) \to x'(t') = \sqrt{\lambda} x(t)
\end{equation}
and show that the action is invariant under this transformation.

\begin{problem}
    \begin{equation}
        \dv{E}{t} = \dot{x}\left( m\ddot{x} - \frac{2 \alpha}{x^3} \right)
    \end{equation}
    From the Lagrange equations, we know that
    \begin{equation}
        \pdv{L}{x} - \dv{t} \pdv{L}{\dot{x}} = \frac{2 \alpha}{x^3} - m\ddot{x} = 0
    \end{equation}
    so
    \begin{equation}
        \dv{E}{t} = (0)\dot{x} = 0
    \end{equation}

    Next, we consider the time scaling transformation. Since $ \dd{t'} = \lambda \dd{t} $, under this transformation,
    \begin{equation}
        \dot{x}'(t') = \dv{t'} x'(t') = \frac{1}{\lambda} \dv{t'}{t} \dv{t'} \sqrt{\lambda} x(t) = \frac{\sqrt{\lambda}}{\lambda} \dot{x}(t)
    \end{equation}
    so
    \begin{align}
        S'(x', \dot{x}') &= \int \dd{t'} \left( \frac{1}{2} m (\dot{x}')^2 - \frac{\alpha}{(x')^2} \right) \\
        &= \int \lambda \dd{t} \left( \frac{1}{2} m \left( \frac{\sqrt{\lambda}}{\lambda} \dot{x} \right)^2 - \frac{\alpha}{(\sqrt{\lambda} x)^2} \right) \\
        &= \int \dd{t} \lambda \left( \frac{1}{2} m \frac{1}{\lambda} \dot{x}^2 - \frac{1}{\lambda} \frac{\alpha}{x^2} \right) \\
        &= \int \dd{t} \left( \frac{1}{2} m\dot{x}^2 - \frac{\alpha}{x^2} \right) = S(x,\dot{x})
    \end{align}
\end{problem}

\section*{4. Noether's Theorem}
Let's use Noethers theorem to determine another conserved quantity, but we have to be a little careful. We are transforming both $ x $ and its argument. When we derive the Noether current, we'd like to keep the initial and final times fixed, so we need to determine the variation in the functional form of $ x $, i.e. $ x'(t) $ and not $ x'(t') $. For an infinitesimal transformation $ \lambda = 1 + \epsilon $,
\begin{equation}
    x'(t') = x'( (1+ \epsilon)t) \approx x'(t) + \dot{x}'(t) \epsilon t \approx x'(t) + \dot{x}(t) \epsilon t
\end{equation}
and
\begin{equation}
    x'(t) = \left( 1 + \frac{1}{2} \epsilon \right) x(t)
\end{equation}
so that
\begin{equation}
    \delta x(t) = x'(t) - x(t) \approx \frac{1}{2} \epsilon x(t) - \dot{x}(t) \epsilon t
\end{equation}

\begin{problem}
    ``4 is not really a problem but sets up the next problems'' (quoth Prof. Rothstein)
\end{problem}
\section*{5. Use the result to show that under this variation, the action is in fact NOT invariant but is equal to a total derivative}
\begin{equation}
    \delta S = \epsilon \int \dd{t} \dv{t}(-tL).
\end{equation}

\begin{problem}
    First, we vary the action:
    \begin{equation}
        \delta S = \int \dd{t} \delta L
    \end{equation}
    where
    \begin{equation}
        \delta L = \fdv{L}{x} \delta x + \fdv{L}{\dot{x}} \delta \dot{x}
    \end{equation}
    We are given $ \delta x = \epsilon \left( \frac{1}{2} x - \dot{x} t \right) $, and
    \begin{equation}
        \delta \dot{x} = \delta \dv{t} x = \dv{t} \delta x = - \epsilon \left( \frac{1}{2} \dot{x} + \ddot{x}t \right)
    \end{equation}
    Therefore
    \begin{equation}
        \delta L = \frac{2 \alpha}{x^3} \epsilon \left( \frac{1}{2} x - \dot{x} t \right) - \epsilon m \dot{x} \left( \frac{1}{2} \dot{x} + \ddot{x} t \right) = \epsilon \left( \frac{\alpha}{x^2} - \frac{2 \alpha \dot{x} t}{x^3} - m \dot{x}\ddot{x} - \frac{1}{2} m \dot{x}^2 \right) = \epsilon \dv{t}(-tL)
    \end{equation}
\end{problem}

\section*{6. Conserved Charge}
This does not mean that there is no conserved charge. Since its a total derivative we can absorb the variation into the charge and derive a new conserved charged. Follow this procedure to show that the new conserved charge is given by
\begin{equation}
    Q = \frac{1}{2} m x\dot{x} - \left( \frac{1}{2} mt\dot{x}^2 + \frac{\alpha t}{x^2} \right)
\end{equation}
\begin{problem}
    We can rewrite Noether's theorem with this extra time derivative term:
    \begin{equation}
        \dv{t} \left[ \pdv{L}{\dot{x}} \delta x \right] + \epsilon \dv{t}\left[ -tL \right] = 0
    \end{equation}
    Expanding this, we find
    \begin{align}
        0 &= \dv{t} \left[ m \dot{x} \epsilon \left( \frac{1}{2} x - \dot{x}t \right)\right] + \epsilon \dv{t}\left[ -tL \right] \\
        Q &= \left[ m \dot{x} \left( \frac{1}{2} x - \dot{x}t \right) \right] - tL \\
        &= \frac{1}{2} m x \dot{x} - \left( \frac{1}{2} mt\dot{x}^2 + \frac{\alpha t}{x^2} \right)
    \end{align}
\end{problem}

\section*{7. Use this result to derive an equation for $ x(t, E, Q) $}
This is truly remarkable, we have found a solution to the equations of motion without doing any work at all!\ No differential equation needs to be solved. This is highly unusual and itâ€™s tough to find systems with this much symmetry.

Notice that for any 1D system that is time translation invariant, we always have one constant of motion. So we can always solve for $ x $ in terms of $ \dot{x} $, and this reduces the problem to one integral. Solve for $ \dot{x} $ in terms of $ E $ and $ V(x) $ and then integrate to get $ t(E,q,q_0) $
\begin{equation}
    t = \pm \int^q_{q_0} \frac{\dd{q}}{\sqrt{2(E-V(q))}}
\end{equation}

\begin{problem}
    We can rewrite this in terms of $ E $:
    \begin{equation}
        Q = \frac{1}{2} mx\dot{x} - t\left( E \right)
    \end{equation}
    and from the energy conservation statement,
    \begin{equation}
        \dot{x} = \pm \sqrt{\frac{2(E x^2 - \alpha)}{m x^2}}
    \end{equation}
    We can then solve for $ x $:
    \begin{equation}
        x(t, E, Q) = \pm \sqrt{\frac{\alpha m + 2 Q^2 + 4 EQt + 2 E^2 t^2}{Em}}
    \end{equation}

    Solving for $ \dot{x} $ in terms of $ E $ and $ V(x) $, we have
    \begin{equation}
        \dot{x} = \pm \sqrt{\frac{2(E x^2 - \alpha)}{m x^2}} = \pm \sqrt{\left( E - \frac{\alpha}{x^2} \frac{2}{m} \right)}
    \end{equation}
    so
    \begin{equation}
        \dd{x} = \sqrt{\left( E - \frac{\alpha}{x^2} \frac{2}{m} \right)} \dd{t}
    \end{equation}
    or
    \begin{equation}
        t = \pm \int_{x_0}^x \frac{1}{\sqrt{\frac{2}{m} (E - V(x))}} \dd{x}
    \end{equation}
    where
    \begin{equation}
        V(x) = \frac{\alpha}{x^2}
    \end{equation}
\end{problem}

\end{document}
